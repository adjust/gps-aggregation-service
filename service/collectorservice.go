// Copyright 2021 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Package collectorservice contains the functions needed for the HTTP service which collects
// reports sent by the browsers.
package collectorservice

import (
	"context"
	"fmt"
	"net/http"
	"sync"
	"time"

	log "github.com/golang/glog"
	"github.com/ugorji/go/codec"
	"github.com/google/privacy-sandbox-aggregation-service/pipeline/dpfbrowsersimulator"
	"github.com/google/privacy-sandbox-aggregation-service/pipeline/ioutils"

	pb "github.com/google/privacy-sandbox-aggregation-service/pipeline/crypto_go_proto"
)

// The struct tags in the following structs need to be consistent with the field names defined in:
// https://github.com/WICG/conversion-measurement-api/blob/main/AGGREGATE.md#aggregate-attribution-reports

// AggregationServicePayload contains the payload for a specific helper server.
type AggregationServicePayload struct {
	Origin string `json:"origin"`
	// Payload is a encrypted CBOR serialized instance of struct dpfaggregator.Payload.
	Payload []byte `json:"payload"`
	KeyID   string `json:"key_id"`
}

// AggregationReport contains the information generated by the browser from a key-value pair,
// which will be used for server-side aggregation.
type AggregationReport struct {
	SourceSite             string `json:"source_site"`
	AttributionDestination string `json:"attribution_destination"`
	// SharedInfo is a CBOR serialized instance of struct SharedInfo.
	SharedInfo []byte                       `json:"shared_info"`
	Payloads   []*AggregationServicePayload `json:"aggregation_service_payloads"`
}

// SharedInfo contains the shared infomation that will be used as the context info for the hybrid encryption.
type SharedInfo struct {
	ScheduledReportTime int64  `json:"scheduled_report_time"`
	PrivacyBudgetKey    string `json:"privacy_budget_key"`
	Version             string `json:"version"`
	ReportingOrigin     string `json:"reporting_origin"`
}

// CollectorHandler handles the HTTPS requests with incoming reports.
//
// The server keeps receiving reports from the browsers and tracks the number of reports per pair
// of helper origins. When the report number reaches the predefined batch size, the reports are
// written into two files, which will be the input of the aggregation service for the corresponding helpers.
type CollectorHandler struct {
	bufferedReportWriter bufferedReportWriter
}

// NewHandler creates a new CollectorHandler with initialized values
func NewHandler(ctx context.Context, batchSize int, batchDir string) *CollectorHandler {
	brw := bufferedReportWriter{
		batchSize: batchSize,
		batchDir:  batchDir,
		wg:        &sync.WaitGroup{},
		reportsCh: make(chan *AggregationReport),
	}
	brw.start(ctx, brw.reportsCh)

	return &CollectorHandler{
		bufferedReportWriter: brw,
	}
}

// Handler helper function to get Handler for http.Server
func (h *CollectorHandler) Handler() http.Handler {
	return h
}

func (h *CollectorHandler) ServeHTTP(w http.ResponseWriter, req *http.Request) {

	report := &AggregationReport{}
	if err := codec.NewDecoder(req.Body, &codec.CborHandle{}).Decode(report); err != nil {
		errMsg := "Failed in decoding CBOR message"
		http.Error(w, errMsg, http.StatusBadRequest)
		log.Error(errMsg, err)
		return
	}

	if got, want := len(report.Payloads), 2; got != want {
		errMsg := fmt.Sprintf("expected %d payloads, got %d", want, got)
		http.Error(w, errMsg, http.StatusBadRequest)
		log.Error(errMsg)
	}

	origin1, origin2 := report.Payloads[0].Origin, report.Payloads[1].Origin
	if origin1 == origin2 {
		errMsg := fmt.Sprintf("secret shares sending to the same helper %q", origin1)
		http.Error(w, errMsg, http.StatusBadRequest)
		log.Error(errMsg)
	}

	h.bufferedReportWriter.reportsCh <- report
}

// Shutdown function used in http.Server.RegisterOnShutdown to close channel and flush
// remaining reports
func (h *CollectorHandler) Shutdown() {
	close(h.bufferedReportWriter.reportsCh)
	h.bufferedReportWriter.wg.Wait()
}

type bufferedReportWriter struct {
	batchSize  int
	bufferSize int
	batchDir   string
	wg         *sync.WaitGroup
	reportsCh  chan *AggregationReport
}

func (brw *bufferedReportWriter) start(ctx context.Context, reportsCh <-chan *AggregationReport) {
	log.Infof("Starting buffered report writer with %v batch size", brw.batchSize)
	batches := make(map[string][]*AggregationReport)

	brw.wg.Add(1)
	go func() {
		for report := range reportsCh {
			origin1, origin2 := report.Payloads[0].Origin, report.Payloads[1].Origin
			if origin1 > origin2 {
				origin1, origin2 = origin2, origin1
			}
			batchKey := fmt.Sprintf("%s+%s", origin1, origin2)
			batches[batchKey] = append(batches[batchKey], report)
			// TODO: harden against batchKey attacks
			if len(batches[batchKey]) == brw.batchSize {
				brw.writeReports(ctx, batchKey, batches[batchKey])
				batches[batchKey] = []*AggregationReport{}
			}
		}
		log.Info("Buffered Report Writer channel closed, flushing remaining reports...")
		for key, batch := range batches {
			if len(batch) > 0 {
				brw.writeReports(ctx, key, batch)
			}
		}
		brw.wg.Done()
	}()
}

func (brw *bufferedReportWriter) writeReports(ctx context.Context, batchKey string, batch []*AggregationReport) {
	reportBatches := make(map[string][]*pb.EncryptedPartialReportDpf, 2)
	for _, report := range batch {
		for _, payload := range report.Payloads {
			reportBatches[payload.Origin] = append(reportBatches[payload.Origin], &pb.EncryptedPartialReportDpf{
				EncryptedReport: &pb.StandardCiphertext{Data: payload.Payload},
				ContextInfo:     report.SharedInfo,
				KeyId:           payload.KeyID,
			})
		}
	}

	timestamp := time.Now().Format(time.RFC3339Nano)

	for origin := range reportBatches {
		log.Infof("Writing batch for %v to: %v", origin, ioutils.JoinPath(brw.batchDir, fmt.Sprintf("%s+%s+%s", batchKey, origin, timestamp)))
		if err := brw.writeBatch(ctx, reportBatches[origin], ioutils.JoinPath(brw.batchDir, fmt.Sprintf("%s+%s+%s", batchKey, origin, timestamp))); err != nil {
			log.Error(err.Error())
			return
		}
	}
}

func (brw *bufferedReportWriter) writeBatch(ctx context.Context, batch []*pb.EncryptedPartialReportDpf, filename string) error {
	var lines []string
	for _, b := range batch {
		line, err := dpfbrowsersimulator.FormatEncryptedPartialReport(b)
		if err != nil {
			return err
		}
		lines = append(lines, line)
	}

	return ioutils.WriteLines(ctx, lines, filename)
}
